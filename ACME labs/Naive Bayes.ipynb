{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed data, % accuracy of my classifier:  92.5\n",
      "Seed data, % accuracy of sklearn classifier:  85.0\n",
      "Spam data, my accuracy:  96.0\n",
      "Spam data, MultinomialNB accuracy:  96.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def prob1():\n",
    "    seed_data = np.loadtxt(\"seeds_dataset.txt\")\n",
    "    # Last column is the type of wheat. First seven are the features\n",
    "    # 0: Area, 1: Perimeter, 2: Compactness, 3: Length, 4: Width, 5: Asymmetry\n",
    "    # 6: Groove length\n",
    "\n",
    "    training, test = cross_validation.train_test_split(seed_data,test_size=40)\n",
    "    probs = np.bincount(training[:,-1].astype(np.int64))[1:].astype(np.float64)/training.shape[0]\n",
    "    logprobs = np.log(probs)\n",
    "\n",
    "    mu = np.vstack([np.mean(training[training[:,-1]==i],axis=0) for i in xrange(1,4)])[:,:-1]\n",
    "    sig = np.vstack([np.var(training[training[:,-1]==i],axis=0) for i in xrange(1,4)])[:,:-1]\n",
    "    \n",
    "    # c_i's are the possible labels 1-3\n",
    "    # x_j's are the features 0-6\n",
    "    # c = argmax over i\\in{1,...,k} log(P(c_i))+sum_j=1^n logP(x_j|c_i)\n",
    "    \n",
    "    # P(x_j|c_i) = np.exp(-(x_j-mu[i,j])**2/(2.0*sig[i,j]))/np.sqrt(2*np.pi*sig[i,j])\n",
    "    \n",
    "    labels = test[:,-1]\n",
    "    predictions = np.zeros_like(labels)\n",
    "    for j in xrange(40):\n",
    "        x = test[j,:-1]\n",
    "    \n",
    "        test_probs = np.zeros(3)\n",
    "        for i in xrange(3):\n",
    "            test_probs[i] = logprobs[i] + np.sum(np.log(np.exp(-(x-mu[i,:])**2/(2.0*sig[i,:]))/np.sqrt(2*np.pi*sig[i,:])))\n",
    "        predictions[j] = np.argmax(test_probs) + 1\n",
    "    \n",
    "    accuracy = 100 - np.count_nonzero(labels-predictions)*2.5\n",
    "    print \"Seed data, % accuracy of my classifier: \", accuracy\n",
    "    return accuracy\n",
    "\n",
    "def prob2():\n",
    "    seed_data = np.loadtxt(\"seeds_dataset.txt\")\n",
    "    training, test = cross_validation.train_test_split(seed_data,test_size=40)\n",
    "    \n",
    "    nb_classifier = GaussianNB()\n",
    "    nb_classifier.fit(training[:,:-1],training[:,-1])\n",
    "    \n",
    "    labels = test[:,-1]\n",
    "    predictions = nb_classifier.predict(test[:,:-1])\n",
    "    \n",
    "    accuracy = 100 - np.count_nonzero(labels-predictions)*2.5\n",
    "    print \"Seed data, % accuracy of sklearn classifier: \", accuracy\n",
    "    return accuracy\n",
    "\n",
    "class naiveBayes(object):\n",
    "    \"\"\"\n",
    "    This class performs Naive Bayes classification for word-count document‚Üê-\n",
    "    features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize a Naive Bayes classifier.\n",
    "        \"\"\"\n",
    "        #self.nb_classifier = GaussianNG()\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        \"\"\"\n",
    "        Fit the parameters according to the labeled training data (X,Y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, n_features)\n",
    "        Each row is the word-count vector for one of the documents\n",
    "        Y : ndarray of shape (n_samples,)\n",
    "        Gives the class label for each instance of training data. Assume class labels\n",
    "        are in {0,1,...,k-1} where k is the number of classes.\n",
    "        \"\"\"\n",
    "        # get prior class probabilities P(c_i)\n",
    "        # (you may wish to store these as a length k vector as a class attribute)\n",
    "        \n",
    "        # get (smoothed) word-class probabilities\n",
    "        # (you may wish to store these in a (k, n_features) matrix as a class attribute)\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        self.P = np.array([(Y==i).mean() for i in set(Y)])\n",
    "        self.n_classes = len(set(Y))\n",
    "        \n",
    "        self.p = np.array([(X[Y==i]).sum(axis=0)+1 for i in xrange(self.n_classes)])\n",
    "        self.p /= self.p.sum(axis=1).reshape(self.p.shape[0],1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class labels of a set of test data.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, n_features)\n",
    "        The test data\n",
    "        Returns\n",
    "        -------\n",
    "        Y : ndarray of shape (n_samples,)\n",
    "        Gives the classification of each row in X\n",
    "        \"\"\"\n",
    "        return np.argmax(np.log(self.P) + X.dot(np.log(self.p).T),axis=1)\n",
    "    \n",
    "def prob4():\n",
    "    features = np.loadtxt(\"SpamFeatures.txt\")\n",
    "    labels = np.loadtxt(\"SpamLabels.txt\")\n",
    "    \n",
    "    nb = naiveBayes()\n",
    "    \n",
    "    test_indices = np.random.randint(0,features.shape[0],500)\n",
    "    train_indices = np.array(list(set(range(features.shape[0])) - set(test_indices)))\n",
    "    \n",
    "    train_vectors = features[train_indices]\n",
    "    train_labels = labels[train_indices]\n",
    "    \n",
    "    test_vectors = features[test_indices]\n",
    "    test_labels = labels[test_indices]\n",
    "    nb.fit(train_vectors, train_labels)\n",
    "    \n",
    "    nb_predicted = nb.predict(test_vectors)\n",
    "    \n",
    "    print \"Spam data, my accuracy: \", 100*np.mean(nb_predicted == test_labels)\n",
    "    \n",
    "    # assume train_vectors, train_labels, and test_vectors are defined\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(train_vectors, train_labels)\n",
    "    mnb_predicted = mnb.predict(test_vectors)\n",
    "    \n",
    "    print \"Spam data, MultinomialNB accuracy: \", 100*np.mean(mnb_predicted == test_labels)\n",
    "\n",
    "prob1()\n",
    "prob2()\n",
    "\n",
    "prob4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
