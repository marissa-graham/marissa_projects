{
 "metadata": {
  "name": "",
  "signature": "sha256:3d7655deb90cd484393d3f2b48b9480cb1ffebc273bc24cbe1ffe82ec08481dd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "from scipy import linalg as la\n",
      "from scipy.optimize import fmin_cg\n",
      "from matplotlib import pyplot as plt\n",
      "\n",
      "def conjugateGradient(b, x, mult):\n",
      "    '''\n",
      "    Minimize .5x^TQx - b^Tx + c using the method of Steepest Descent.\n",
      "    Equivalently, solve Qx = b.\n",
      "    Inputs:\n",
      "        b -- length n array\n",
      "        x -- length n array, the inital guess\n",
      "        mult -- a callable function object that performs matrix-vector multiplication by Q.\n",
      "                i.e., mult(d) returns Qd.\n",
      "    Returns:\n",
      "        a numpy array, the solution to Qx = b.\n",
      "    '''\n",
      "    n = len(x)\n",
      "    x_k = x\n",
      "    r_k = mult(x_k) - b\n",
      "    d_k = -r_k\n",
      "    k = 0\n",
      "    zero = np.zeros(n)\n",
      "    while ~np.allclose(r_k, zero, rtol=1E-20, atol=1E-30) and k <= 10*n:\n",
      "        Qd = mult(d_k)\n",
      "        rkTrk = np.dot(r_k, r_k)\n",
      "        \n",
      "        alpha = rkTrk/np.dot(d_k, Qd)\n",
      "        x_k = x_k + alpha*d_k\n",
      "        r_K = r_k + alpha*Qd\n",
      "        beta = np.dot(r_K,r_K)/rkTrk\n",
      "        d_k = -r_K + beta*d_k\n",
      "        r_k = r_K\n",
      "        k += 1\n",
      "    return x_k\n",
      "\n",
      "def test1(n):\n",
      "    A = np.random.rand(n,n)\n",
      "    Q = A.T.dot(A)\n",
      "    b = np.random.random(n)\n",
      "    if la.det(Q) == 0:\n",
      "        return \"Singular matrix generated. Try again.\"\n",
      "    def mult(x):\n",
      "        return Q.dot(x)\n",
      "    x0 = np.random.random(n)\n",
      "    x = conjugateGradient(b, x0, mult)\n",
      "    print np.allclose(x, la.solve(Q,b))\n",
      "    # Compare timings. la.solve() is predictably much faster\n",
      "    #%timeit conjugateGradient(b, x0, mult)\n",
      "    #%timeit la.solve(Q,b)\n",
      "    \n",
      "    \n",
      "def linRegression():\n",
      "    '''http://www.itl.nist.gov/div898/strd/lls/data/LINKS/v-Longley.shtml'''\n",
      "    '''\n",
      "    Use your conjugate gradient method to find the linear regression solution to the data in the\n",
      "    data file. Plot the solution with the data.\n",
      "    ''' \n",
      "    data = np.loadtxt('linregression.txt')\n",
      "    y = data[:,0]\n",
      "    x = data[:,1:]\n",
      "    Q = x.T.dot(x)\n",
      "    b = x.T.dot(y)#.reshape(x.shape[1],1)\n",
      "    x0 = np.random.random(x.shape[1])#.reshape(x.shape[1],1)\n",
      "    def mult(x):\n",
      "        return np.dot(Q,x)\n",
      "    print b.shape\n",
      "    print x0.shape\n",
      "    print Q.shape\n",
      "    print mult(x0).shape\n",
      "    soln = conjugateGradient(b, x0, mult)\n",
      "    return soln\n",
      "\n",
      "def logRegression():\n",
      "    '''\n",
      "    Return the output of fmin_cg\n",
      "    '''    \n",
      "    data = np.loadtxt('logregression.txt')\n",
      "    y = data[:,0]\n",
      "    x = np.ones_like(data)\n",
      "    x[:,1:] = data[:,1:]\n",
      "    def objective(b):\n",
      "        '''Return -1*l(b), where l is the log likelihood.'''\n",
      "        return (np.log(1+np.exp(x.dot(b))) - y*(x.dot(b))).sum()\n",
      "    guess = np.array([1.,1.,1.,1.])\n",
      "    return fmin_cg(objective, guess)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Optimization terminated successfully.\n",
        "         Current function value: 338.945679\n",
        "         Iterations: 19\n",
        "         Function evaluations: 234\n",
        "         Gradient evaluations: 39\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "array([-0.41307585,  0.92181456,  0.21007447, -0.55791853])"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}